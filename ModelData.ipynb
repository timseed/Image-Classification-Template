{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2806d095-56f5-46ec-bee6-b035de70b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "with open('Image-Dev-01.pkl','rb') as ifp:\n",
    "    files,y_unique,X,y = pickle.load(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45849a8-67f7-43ca-9cce-9d15b14bb260",
   "metadata": {},
   "source": [
    "# Build Keras Model\n",
    "\n",
    "We first need to split our data into training and test (sometimes called validation) segments.\n",
    "\n",
    "There is an easy way to do this - train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decc5e35-a986-425e-85eb-afd2263cf858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have   759 Training samples\n",
      "We have   375 Test samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(f\"We have {X_train.shape[0]:5d} Training samples\")\n",
    "print(f\"We have {X_test.shape[0]:5d} Test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7585028-4497-44f8-a55d-5105cf317c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are trying to predict 3 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(list(set(y)))\n",
    "print(f\"We are trying to predict {num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d364c9b9-d3c3-475c-b51f-bd23da86463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , Convolution2D,MaxPool2D , Flatten , Dropout , MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import adam_v2 \n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b86fb67-7fe4-429e-9e1f-3fcd2e5fb4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 32)        2336      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16928)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                203148    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 39        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,603\n",
      "Trainable params: 205,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 32)        2336      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16928)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                203148    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 39        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,603\n",
      "Trainable params: 205,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Make 64 Output Channels using a kernel size of size of 5,5\n",
    "# Kernel should be an odd number\n",
    "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=(X_train[1].shape)))\n",
    "# Step - 2 Pooling\n",
    "# Set pool_size smaller than the kernel size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Increase the number of channels that the 1st Conv2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes*4, activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dense(num_classes, activation='softmax',kernel_initializer='uniform'))\n",
    "model.summary()\n",
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) , metrics = ['accuracy'])\n",
    "\n",
    "# # simple early stopping\n",
    "# #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "# # More patient Early stopping \n",
    "model.summary()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20) #Little Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ee21aa8-ffcc-403f-90a1-3cb3eed6675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.0979 - accuracy: 0.3505 - val_loss: 1.0917 - val_accuracy: 0.3093\n",
      "Epoch 2/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.0406 - accuracy: 0.5059 - val_loss: 0.9235 - val_accuracy: 0.6720\n",
      "Epoch 3/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.8097 - accuracy: 0.6126 - val_loss: 0.6588 - val_accuracy: 0.6587\n",
      "Epoch 4/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.6562 - accuracy: 0.6324 - val_loss: 0.5567 - val_accuracy: 0.7147\n",
      "Epoch 5/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.5611 - accuracy: 0.6798 - val_loss: 0.5053 - val_accuracy: 0.7067\n",
      "Epoch 6/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.4938 - accuracy: 0.7167 - val_loss: 0.4505 - val_accuracy: 0.7440\n",
      "Epoch 7/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.4542 - accuracy: 0.7457 - val_loss: 0.4318 - val_accuracy: 0.7413\n",
      "Epoch 8/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.4236 - accuracy: 0.7813 - val_loss: 0.4445 - val_accuracy: 0.7227\n",
      "Epoch 9/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.4121 - accuracy: 0.7668 - val_loss: 0.3787 - val_accuracy: 0.8080\n",
      "Epoch 10/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.3905 - accuracy: 0.7971 - val_loss: 0.3596 - val_accuracy: 0.8400\n",
      "Epoch 11/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.3757 - accuracy: 0.8090 - val_loss: 0.3477 - val_accuracy: 0.8213\n",
      "Epoch 12/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.3561 - accuracy: 0.8353 - val_loss: 0.3186 - val_accuracy: 0.8987\n",
      "Epoch 13/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.3314 - accuracy: 0.8603 - val_loss: 0.2992 - val_accuracy: 0.8907\n",
      "Epoch 14/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.3119 - accuracy: 0.8551 - val_loss: 0.3241 - val_accuracy: 0.8187\n",
      "Epoch 15/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.3082 - accuracy: 0.8458 - val_loss: 0.2815 - val_accuracy: 0.9040\n",
      "Epoch 16/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.2904 - accuracy: 0.8775 - val_loss: 0.2580 - val_accuracy: 0.8907\n",
      "Epoch 17/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.2699 - accuracy: 0.8920 - val_loss: 0.2390 - val_accuracy: 0.9307\n",
      "Epoch 18/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.2510 - accuracy: 0.8972 - val_loss: 0.2965 - val_accuracy: 0.8293\n",
      "Epoch 19/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.2404 - accuracy: 0.8906 - val_loss: 0.2228 - val_accuracy: 0.8987\n",
      "Epoch 20/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.2224 - accuracy: 0.9065 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 21/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.2058 - accuracy: 0.9275 - val_loss: 0.2097 - val_accuracy: 0.8907\n",
      "Epoch 22/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.1876 - accuracy: 0.9262 - val_loss: 0.1630 - val_accuracy: 0.9493\n",
      "Epoch 23/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.1881 - accuracy: 0.9262 - val_loss: 0.1928 - val_accuracy: 0.8987\n",
      "Epoch 24/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.1808 - accuracy: 0.9315 - val_loss: 0.1521 - val_accuracy: 0.9573\n",
      "Epoch 25/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.1594 - accuracy: 0.9381 - val_loss: 0.1562 - val_accuracy: 0.9227\n",
      "Epoch 26/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.1536 - accuracy: 0.9460 - val_loss: 0.1419 - val_accuracy: 0.9520\n",
      "Epoch 27/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.1496 - accuracy: 0.9328 - val_loss: 0.1733 - val_accuracy: 0.9067\n",
      "Epoch 28/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.1290 - accuracy: 0.9499 - val_loss: 0.1024 - val_accuracy: 0.9680\n",
      "Epoch 29/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.1148 - accuracy: 0.9671 - val_loss: 0.0946 - val_accuracy: 0.9760\n",
      "Epoch 30/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.1239 - accuracy: 0.9447 - val_loss: 0.0874 - val_accuracy: 0.9813\n",
      "Epoch 31/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.0954 - accuracy: 0.9723 - val_loss: 0.0819 - val_accuracy: 0.9840\n",
      "Epoch 32/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0917 - accuracy: 0.9723 - val_loss: 0.0768 - val_accuracy: 0.9840\n",
      "Epoch 33/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0960 - accuracy: 0.9697 - val_loss: 0.0770 - val_accuracy: 0.9813\n",
      "Epoch 34/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0728 - accuracy: 0.9829 - val_loss: 0.0660 - val_accuracy: 0.9813\n",
      "Epoch 35/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 0.0600 - val_accuracy: 0.9867\n",
      "Epoch 36/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0792 - accuracy: 0.9736 - val_loss: 0.0544 - val_accuracy: 0.9920\n",
      "Epoch 37/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.0595 - val_accuracy: 0.9813\n",
      "Epoch 38/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0731 - accuracy: 0.9763 - val_loss: 0.0540 - val_accuracy: 0.9787\n",
      "Epoch 39/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.0527 - accuracy: 0.9947 - val_loss: 0.0462 - val_accuracy: 0.9920\n",
      "Epoch 40/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0455 - accuracy: 0.9921 - val_loss: 0.0663 - val_accuracy: 0.9653\n",
      "Epoch 41/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 0.0563 - val_accuracy: 0.9787\n",
      "Epoch 42/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 0.0670 - val_accuracy: 0.9707\n",
      "Epoch 43/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0423 - val_accuracy: 0.9893\n",
      "Epoch 44/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0388 - accuracy: 0.9934 - val_loss: 0.0466 - val_accuracy: 0.9840\n",
      "Epoch 45/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0353 - accuracy: 0.9921 - val_loss: 0.0527 - val_accuracy: 0.9760\n",
      "Epoch 46/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 0.0447 - val_accuracy: 0.9813\n",
      "Epoch 47/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0278 - accuracy: 0.9947 - val_loss: 0.0521 - val_accuracy: 0.9760\n",
      "Epoch 48/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0318 - accuracy: 0.9921 - val_loss: 0.4136 - val_accuracy: 0.8693\n",
      "Epoch 49/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0400 - accuracy: 0.9908 - val_loss: 0.0614 - val_accuracy: 0.9680\n",
      "Epoch 50/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
      "Epoch 51/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.0382 - val_accuracy: 0.9787\n",
      "Epoch 52/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.0188 - val_accuracy: 0.9973\n",
      "Epoch 53/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9973\n",
      "Epoch 54/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0406 - accuracy: 0.9842 - val_loss: 0.0178 - val_accuracy: 0.9973\n",
      "Epoch 55/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0223 - accuracy: 0.9908 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 56/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.0195 - val_accuracy: 0.9920\n",
      "Epoch 57/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.0228 - val_accuracy: 0.9893\n",
      "Epoch 58/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 0.0314 - val_accuracy: 0.9813\n",
      "Epoch 59/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 60/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0519 - accuracy: 0.9908 - val_loss: 0.0585 - val_accuracy: 0.9733\n",
      "Epoch 61/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0186 - val_accuracy: 0.9920\n",
      "Epoch 62/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 63/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.3142 - val_accuracy: 0.8987\n",
      "Epoch 64/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 65/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0132 - val_accuracy: 0.9947\n",
      "Epoch 66/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 67/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9600\n",
      "Epoch 68/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0224 - val_accuracy: 0.9867\n",
      "Epoch 69/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0168 - accuracy: 0.9934 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 70/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 71/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 72/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 73/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0193 - accuracy: 0.9908 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 74/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 75/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9893\n",
      "Epoch 76/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 77/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 78/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 79/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 80/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0151 - accuracy: 0.9934 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
      "Epoch 81/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 82/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 83/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0074 - accuracy: 0.9960 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
      "Epoch 84/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 85/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 86/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 0.0364 - val_accuracy: 0.9840\n",
      "Epoch 87/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 88/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 6.2421e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 89/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 90/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 4.7579e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 91/400\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 92/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 5.9975e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 93/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 94/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 5.4560e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 95/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 96/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 3.6618e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 97/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.5940e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 98/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.8109e-04 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9840\n",
      "Epoch 99/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 100/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 101/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.8642e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 102/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.5200e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 103/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 104/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3915e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 105/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0971e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 106/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9920\n",
      "Epoch 107/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.6540e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 108/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9749e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 109/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 110/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8058e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 111/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8658e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 112/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 113/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8246e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 114/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.5774e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 115/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0197 - accuracy: 0.9974 - val_loss: 0.0086 - val_accuracy: 0.9973\n",
      "Epoch 116/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.5003e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 117/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.2699e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 118/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7497e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9867\n",
      "Epoch 119/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 120/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.2589e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 121/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.0810e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 122/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3407e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 123/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 124/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.1695e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 125/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 9.3215e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 126/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.1403e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9867\n",
      "Epoch 127/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3915e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 128/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0999 - accuracy: 0.9881 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 129/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.0435e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 130/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 9.5823e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 131/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 7.7286e-05 - accuracy: 1.0000 - val_loss: 8.8131e-04 - val_accuracy: 1.0000\n",
      "Epoch 132/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0138 - accuracy: 0.9934 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
      "Epoch 133/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.3183e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 134/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 8.1460e-05 - accuracy: 1.0000 - val_loss: 9.0024e-04 - val_accuracy: 1.0000\n",
      "Epoch 135/400\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 7.3649e-05 - accuracy: 1.0000 - val_loss: 8.8893e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0042 - accuracy: 0.9960 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 137/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.2798e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 138/400\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 6.3842e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 139/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 140/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 6.8795e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 141/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 5.0462e-05 - accuracy: 1.0000 - val_loss: 9.9681e-04 - val_accuracy: 1.0000\n",
      "Epoch 142/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.5885e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 143/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 8.7795e-04 - val_accuracy: 1.0000\n",
      "Epoch 144/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.9611e-05 - accuracy: 1.0000 - val_loss: 8.3015e-04 - val_accuracy: 1.0000\n",
      "Epoch 145/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.6590e-05 - accuracy: 1.0000 - val_loss: 6.7447e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 8.8050e-05 - accuracy: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.9067\n",
      "Epoch 147/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0285 - accuracy: 0.9947 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 148/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 6.9004e-05 - accuracy: 1.0000 - val_loss: 6.5964e-04 - val_accuracy: 1.0000\n",
      "Epoch 149/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.6855e-05 - accuracy: 1.0000 - val_loss: 7.1466e-04 - val_accuracy: 1.0000\n",
      "Epoch 150/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.3324e-05 - accuracy: 1.0000 - val_loss: 6.3793e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 152/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.8247e-05 - accuracy: 1.0000 - val_loss: 6.6198e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.2390e-05 - accuracy: 1.0000 - val_loss: 6.5968e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.6900e-05 - accuracy: 1.0000 - val_loss: 7.7424e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 8.7751e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.6311e-05 - accuracy: 1.0000 - val_loss: 6.6741e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.9324e-05 - accuracy: 1.0000 - val_loss: 6.2961e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.3867e-05 - accuracy: 1.0000 - val_loss: 6.7812e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.7231e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 160/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 161/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 6.0043e-05 - accuracy: 1.0000 - val_loss: 8.4464e-04 - val_accuracy: 1.0000\n",
      "Epoch 162/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.1188e-05 - accuracy: 1.0000 - val_loss: 3.9865e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0159e-05 - accuracy: 1.0000 - val_loss: 4.1880e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8345e-05 - accuracy: 1.0000 - val_loss: 6.3787e-04 - val_accuracy: 1.0000\n",
      "Epoch 165/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 166/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1609e-05 - accuracy: 1.0000 - val_loss: 5.5127e-04 - val_accuracy: 1.0000\n",
      "Epoch 167/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.5758e-05 - accuracy: 1.0000 - val_loss: 6.4030e-04 - val_accuracy: 1.0000\n",
      "Epoch 168/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.5087e-05 - accuracy: 1.0000 - val_loss: 7.6328e-04 - val_accuracy: 1.0000\n",
      "Epoch 169/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 7.4025e-04 - val_accuracy: 1.0000\n",
      "Epoch 170/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.8262e-05 - accuracy: 1.0000 - val_loss: 5.3676e-04 - val_accuracy: 1.0000\n",
      "Epoch 171/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8040e-05 - accuracy: 1.0000 - val_loss: 3.5213e-04 - val_accuracy: 1.0000\n",
      "Epoch 172/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.2029e-05 - accuracy: 1.0000 - val_loss: 3.3490e-04 - val_accuracy: 1.0000\n",
      "Epoch 173/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.0467e-05 - accuracy: 1.0000 - val_loss: 3.6290e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.9974 - val_loss: 0.3548 - val_accuracy: 0.9520\n",
      "Epoch 175/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 5.4043e-04 - val_accuracy: 1.0000\n",
      "Epoch 176/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.2593e-05 - accuracy: 1.0000 - val_loss: 5.0544e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.1307e-05 - accuracy: 1.0000 - val_loss: 4.5728e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.0088e-05 - accuracy: 1.0000 - val_loss: 4.2703e-04 - val_accuracy: 1.0000\n",
      "Epoch 179/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 9.1599e-06 - accuracy: 1.0000 - val_loss: 4.7155e-04 - val_accuracy: 1.0000\n",
      "Epoch 180/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.2358e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9947\n",
      "Epoch 181/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 8.4828e-04 - val_accuracy: 1.0000\n",
      "Epoch 182/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.7731e-05 - accuracy: 1.0000 - val_loss: 2.8581e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.2981e-05 - accuracy: 1.0000 - val_loss: 2.5899e-04 - val_accuracy: 1.0000\n",
      "Epoch 184/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 9.4024e-06 - accuracy: 1.0000 - val_loss: 2.9274e-04 - val_accuracy: 1.0000\n",
      "Epoch 185/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.0070e-05 - accuracy: 1.0000 - val_loss: 4.4784e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 4.0668e-04 - val_accuracy: 1.0000\n",
      "Epoch 187/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 4.2029e-05 - accuracy: 1.0000 - val_loss: 2.5578e-04 - val_accuracy: 1.0000\n",
      "Epoch 188/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.2807e-05 - accuracy: 1.0000 - val_loss: 3.2569e-04 - val_accuracy: 1.0000\n",
      "Epoch 189/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.1091e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 190/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8995e-05 - accuracy: 1.0000 - val_loss: 1.6413e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 6.5151e-06 - accuracy: 1.0000 - val_loss: 2.0985e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 6.4656e-06 - accuracy: 1.0000 - val_loss: 4.7699e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 2.1139e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.3245e-05 - accuracy: 1.0000 - val_loss: 1.4505e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 6.0786e-06 - accuracy: 1.0000 - val_loss: 1.4287e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.5973e-06 - accuracy: 1.0000 - val_loss: 1.4660e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.9326e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.3288e-06 - accuracy: 1.0000 - val_loss: 2.9391e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.0428e-06 - accuracy: 1.0000 - val_loss: 2.3250e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.9041e-06 - accuracy: 1.0000 - val_loss: 1.8752e-04 - val_accuracy: 1.0000\n",
      "Epoch 201/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.8613e-06 - accuracy: 1.0000 - val_loss: 1.4643e-04 - val_accuracy: 1.0000\n",
      "Epoch 202/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0246 - accuracy: 0.9895 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 203/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.0635e-05 - accuracy: 1.0000 - val_loss: 7.5815e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/400\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.7454e-05 - accuracy: 1.0000 - val_loss: 3.8843e-04 - val_accuracy: 1.0000\n",
      "Epoch 205/400\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 7.5844e-06 - accuracy: 1.0000 - val_loss: 2.3315e-04 - val_accuracy: 1.0000\n",
      "Epoch 206/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.4482e-06 - accuracy: 1.0000 - val_loss: 2.2857e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.7532e-06 - accuracy: 1.0000 - val_loss: 2.4297e-04 - val_accuracy: 1.0000\n",
      "Epoch 208/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 7.9548e-06 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9867\n",
      "Epoch 209/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0264 - accuracy: 0.9960 - val_loss: 0.0133 - val_accuracy: 0.9893\n",
      "Epoch 210/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.5868e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 211/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.4942e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 212/400\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.4132e-05 - accuracy: 1.0000 - val_loss: 6.7490e-04 - val_accuracy: 1.0000\n",
      "Epoch 213/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 4.5392e-06 - accuracy: 1.0000 - val_loss: 2.3757e-04 - val_accuracy: 1.0000\n",
      "Epoch 214/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1396e-06 - accuracy: 1.0000 - val_loss: 1.7008e-04 - val_accuracy: 1.0000\n",
      "Epoch 215/400\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0234e-06 - accuracy: 1.0000 - val_loss: 1.6944e-04 - val_accuracy: 1.0000\n",
      "Epoch 215: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 400 , validation_data = (X_test, y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18e512c8-b725-43fe-8dae-065866d481e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48bd739-0329-4caf-ba93-9af8a0480e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/v0.0a/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model/v0.0a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b12b9-0595-4152-9d02-a5dcd7f019ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03dcf1-8ca5-48b8-b422-4eaaa9d930c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "pyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
